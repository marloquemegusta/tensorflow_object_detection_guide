{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instalación de paquetes y verificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrats, you are using 3.7.9  which is compatible with this notebook\n"
     ]
    }
   ],
   "source": [
    "# comprobamos que la versión de python sea inferior a 3.8, ya que para usar tensorflow 1.15 se recomienda usar python\n",
    "# 3.7 o inferior\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import string\n",
    "from object_detection.utils import label_map_util\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "python_version=sys.version.split(\"(\")[0]\n",
    "if int(sys.version.split(\".\")[1])>7:\n",
    "    print(\"you are using a python version higer than 3.7.x, please install python 3.7.x\")\n",
    "else:\n",
    "    print(\"congrats, you are using {} which is compatible with this notebook\".format(python_version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.7.9: /home/bigdata/anaconda3/envs/tf1/bin/python3\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "/home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py:669: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(wrapped_dict, collections.Mapping):\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF1Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF1Test.test_session\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 21 tests in 0.086s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# si todo sale bien,el test debería correr y los resultados aparecerán debajo. Es normal si se salta alguno de los tests \n",
    "# que hay\n",
    "!python3 models/research/object_detection/builders/model_builder_tf1_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"training_masks\"\n",
    "images_dir  = \"images_masks\"\n",
    "label_map = label_map_util.load_labelmap(training_dir+\"/label_map.pbtxt\")\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "n_classes=len(label_map_dict.keys())\n",
    "images_format=glob.glob(images_dir+\"/*\")[-1].split(\".\")[-1]\n",
    "config_file_name=\"mask_rcnn_inception_v2_coco.config\"\n",
    "network_name=\"_\".join(config_file_name.split(\"_\")[0:2])\n",
    "inference_graph_dir = \"inference_graph_{}_{}_{}\".format(network_name,datetime.now().day, datetime.now().month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borramos todos los pares de imágenes y anotaciones json donde no se haya detectado nada, ya que estos archivos sin\n",
    "# detecciones producen un error en pasos posteriores\n",
    "for json_path in glob.glob(images_dir+\"/*.json\"):\n",
    "    with open(json_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        if data[\"shapes\"]==[]:\n",
    "            print (\"removing{} and {}\".format(json_path,json_path.replace(\"json\",\"JPG\")))\n",
    "            os.remove(json_path)\n",
    "            os.remove(json_path.replace(\"json\",\"JPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borramos las carpetas de train test y validación si es que existían de un entrenamiento anterior\n",
    "!rm -rf {images_dir}/train {images_dir}/test {images_dir}/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesfully created validation split using:  15.0 % of data\n",
      "succesfully created test split using:  10.0 % of data\n",
      "succesfully created train split using:  75.0 % of data\n",
      "\u001b[34;42mimages_masks\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "\n",
      "3 directories\n"
     ]
    }
   ],
   "source": [
    "# vamos a dividir nuestras imágenes y anotaciones en splits de train, test y validación.\n",
    "# los argumentos -vr y -tr indican respectivamente los porcentajes de datos reservados para validación y test.\n",
    "# el argumento -f indica el formato de las imágenes\n",
    "!python3 scripts/train_test_split.py -i {images_dir} -o {images_dir} -tr 0.1 -vr 0.15 -f {images_format}\n",
    "!tree -d {images_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: images_masks/train/coco\n",
      "Generating dataset from: images_masks/train/video2_frame9780.json\n",
      "Generating dataset from: images_masks/train/video1_frame8950.json\n",
      "Generating dataset from: images_masks/train/video2_frame8400.json\n",
      "Generating dataset from: images_masks/train/video2_frame5100.json\n",
      "Generating dataset from: images_masks/train/video2_frame2100.json\n",
      "Generating dataset from: images_masks/train/video1_frame4500.json\n",
      "Generating dataset from: images_masks/train/video2_frame1080.json\n",
      "Generating dataset from: images_masks/train/video2_frame6780.json\n",
      "Generating dataset from: images_masks/train/video1_frame9350.json\n",
      "Generating dataset from: images_masks/train/video2_frame2580.json\n",
      "Generating dataset from: images_masks/train/video2_frame8640.json\n",
      "Generating dataset from: images_masks/train/video1_frame3000.json\n",
      "Generating dataset from: images_masks/train/video1_frame8400.json\n",
      "Generating dataset from: images_masks/train/video2_frame7020.json\n",
      "Generating dataset from: images_masks/train/video1_frame6900.json\n",
      "Generating dataset from: images_masks/train/video2_frame5460.json\n",
      "Generating dataset from: images_masks/train/video1_frame3650.json\n",
      "Generating dataset from: images_masks/train/video2_frame3540.json\n",
      "Generating dataset from: images_masks/train/video1_frame8750.json\n",
      "Generating dataset from: images_masks/train/video2_frame2940.json\n",
      "Generating dataset from: images_masks/train/video1_frame2500.json\n",
      "Generating dataset from: images_masks/train/video1_frame8200.json\n",
      "Generating dataset from: images_masks/train/video2_frame6060.json\n",
      "Generating dataset from: images_masks/train/video1_frame9050.json\n",
      "Generating dataset from: images_masks/train/video2_frame6240.json\n",
      "Generating dataset from: images_masks/train/video2_frame5760.json\n",
      "Generating dataset from: images_masks/train/video1_frame2400.json\n",
      "Generating dataset from: images_masks/train/video6_frame10020.json\n",
      "Generating dataset from: images_masks/train/video2_frame4860.json\n",
      "Generating dataset from: images_masks/train/video4_frame10560.json\n",
      "Generating dataset from: images_masks/train/video1_frame2250.json\n",
      "Generating dataset from: images_masks/train/video1_frame7600.json\n",
      "Generating dataset from: images_masks/train/video2_frame1980.json\n",
      "Generating dataset from: images_masks/train/video2_frame1740.json\n",
      "Generating dataset from: images_masks/train/video1_frame1500.json\n",
      "Generating dataset from: images_masks/train/video1_frame7100.json\n",
      "Generating dataset from: images_masks/train/video1_frame9100.json\n",
      "Generating dataset from: images_masks/train/video2_frame4260.json\n",
      "Generating dataset from: images_masks/train/video2_frame6000.json\n",
      "Generating dataset from: images_masks/train/video4_frame1440.json\n",
      "Generating dataset from: images_masks/train/video6_frame10260.json\n",
      "Generating dataset from: images_masks/train/video2_frame2340.json\n",
      "Generating dataset from: images_masks/train/video2_frame6120.json\n",
      "Generating dataset from: images_masks/train/video1_frame3750.json\n",
      "Generating dataset from: images_masks/train/video2_frame1620.json\n",
      "Generating dataset from: images_masks/train/video2_frame8280.json\n",
      "Generating dataset from: images_masks/train/video2_frame4500.json\n",
      "Generating dataset from: images_masks/train/video2_frame3000.json\n",
      "Generating dataset from: images_masks/train/video1_frame7250.json\n",
      "Generating dataset from: images_masks/train/video1_frame2600.json\n",
      "Generating dataset from: images_masks/train/video2_frame8160.json\n",
      "Generating dataset from: images_masks/train/video2_frame6600.json\n",
      "Generating dataset from: images_masks/train/video1_frame7950.json\n",
      "Generating dataset from: images_masks/train/video2_frame1020.json\n",
      "Generating dataset from: images_masks/train/video1_frame9800.json\n",
      "Generating dataset from: images_masks/train/video2_frame6300.json\n",
      "Generating dataset from: images_masks/train/video4_frame1140.json\n",
      "Generating dataset from: images_masks/train/video2_frame3840.json\n",
      "Generating dataset from: images_masks/train/video1_frame4900.json\n",
      "Generating dataset from: images_masks/train/video2_frame2880.json\n",
      "Generating dataset from: images_masks/train/video2_frame1440.json\n",
      "Generating dataset from: images_masks/train/video1_frame9600.json\n",
      "Generating dataset from: images_masks/train/video2_frame7860.json\n",
      "Generating dataset from: images_masks/train/video2_frame6420.json\n",
      "Generating dataset from: images_masks/train/video1_frame2050.json\n",
      "Generating dataset from: images_masks/train/video2_frame8340.json\n",
      "Generating dataset from: images_masks/train/video2_frame7140.json\n",
      "Generating dataset from: images_masks/train/video2_frame2160.json\n",
      "Generating dataset from: images_masks/train/video2_frame8580.json\n",
      "Generating dataset from: images_masks/train/video2_frame7740.json\n",
      "Generating dataset from: images_masks/train/video3_frame10260.json\n",
      "Generating dataset from: images_masks/train/video2_frame8040.json\n",
      "Generating dataset from: images_masks/train/video6_frame10140.json\n",
      "Generating dataset from: images_masks/train/video1_frame9400.json\n",
      "Generating dataset from: images_masks/train/video1_frame5350.json\n",
      "Generating dataset from: images_masks/train/video1_frame4650.json\n",
      "Generating dataset from: images_masks/train/video1_frame7000.json\n",
      "Generating dataset from: images_masks/train/video1_frame7300.json\n",
      "Generating dataset from: images_masks/train/video2_frame3180.json\n",
      "Generating dataset from: images_masks/train/video2_frame4440.json\n",
      "Generating dataset from: images_masks/train/video4_frame10080.json\n",
      "Generating dataset from: images_masks/train/video3_frame10320.json\n",
      "Generating dataset from: images_masks/train/video2_frame9660.json\n",
      "Generating dataset from: images_masks/train/video4_frame1260.json\n",
      "Generating dataset from: images_masks/train/video1_frame1150.json\n",
      "Generating dataset from: images_masks/train/video2_frame3960.json\n",
      "Generating dataset from: images_masks/train/video2_frame8100.json\n",
      "Generating dataset from: images_masks/train/video2_frame5640.json\n",
      "Generating dataset from: images_masks/train/video1_frame7500.json\n",
      "Generating dataset from: images_masks/train/video1_frame9500.json\n",
      "Generating dataset from: images_masks/train/video1_frame7800.json\n",
      "Generating dataset from: images_masks/train/video1_frame2100.json\n",
      "Generating dataset from: images_masks/train/video1_frame8350.json\n",
      "Generating dataset from: images_masks/train/video2_frame3360.json\n",
      "Generating dataset from: images_masks/train/video1_frame9750.json\n",
      "Generating dataset from: images_masks/train/video1_frame8000.json\n",
      "Generating dataset from: images_masks/train/video1_frame4350.json\n",
      "Generating dataset from: images_masks/train/video2_frame4020.json\n",
      "Generating dataset from: images_masks/train/video1_frame900.json\n",
      "Generating dataset from: images_masks/train/video2_frame3300.json\n",
      "Generating dataset from: images_masks/train/video1_frame4600.json\n",
      "Generating dataset from: images_masks/train/video2_frame5580.json\n",
      "Generating dataset from: images_masks/train/video2_frame1320.json\n",
      "Generating dataset from: images_masks/train/video1_frame10100.json\n",
      "Generating dataset from: images_masks/train/video1_frame7150.json\n",
      "Generating dataset from: images_masks/train/video1_frame4000.json\n",
      "Generating dataset from: images_masks/train/video1_frame5250.json\n",
      "Generating dataset from: images_masks/train/video1_frame8150.json\n",
      "Generating dataset from: images_masks/train/video2_frame1500.json\n",
      "Generating dataset from: images_masks/train/video1_frame5450.json\n",
      "Generating dataset from: images_masks/train/video2_frame3600.json\n",
      "Generating dataset from: images_masks/train/video2_frame5520.json\n",
      "Generating dataset from: images_masks/train/video1_frame2550.json\n",
      "Generating dataset from: images_masks/train/video1_frame10050.json\n",
      "Generating dataset from: images_masks/train/video1_frame7850.json\n",
      "Generating dataset from: images_masks/train/video2_frame7620.json\n",
      "Generating dataset from: images_masks/train/video1_frame3800.json\n",
      "Generating dataset from: images_masks/train/video1_frame9300.json\n",
      "Generating dataset from: images_masks/train/video2_frame2460.json\n",
      "Generating dataset from: images_masks/train/video2_frame7440.json\n",
      "Generating dataset from: images_masks/train/video1_frame10300.json\n",
      "Generating dataset from: images_masks/train/video1_frame9450.json\n",
      "Generating dataset from: images_masks/train/video1_frame4850.json\n",
      "Generating dataset from: images_masks/train/video1_frame1200.json\n",
      "Generating dataset from: images_masks/train/video1_frame8650.json\n",
      "Generating dataset from: images_masks/train/video2_frame5160.json\n",
      "Generating dataset from: images_masks/train/video1_frame5700.json\n",
      "Generating dataset from: images_masks/train/video3_frame10200.json\n",
      "Generating dataset from: images_masks/train/video1_frame8600.json\n",
      "Generating dataset from: images_masks/train/video1_frame8500.json\n",
      "Generating dataset from: images_masks/train/video4_frame10680.json\n",
      "Generating dataset from: images_masks/train/video4_frame1380.json\n",
      "Generating dataset from: images_masks/train/video2_frame1560.json\n",
      "Generating dataset from: images_masks/train/video2_frame4800.json\n",
      "Generating dataset from: images_masks/train/video1_frame2950.json\n",
      "Generating dataset from: images_masks/train/video1_frame3350.json\n",
      "Generating dataset from: images_masks/train/video2_frame7500.json\n",
      "Generating dataset from: images_masks/train/video2_frame3720.json\n",
      "Generating dataset from: images_masks/train/video1_frame3900.json\n",
      "Generating dataset from: images_masks/train/video2_frame4140.json\n",
      "Generating dataset from: images_masks/train/video1_frame8300.json\n",
      "Generating dataset from: images_masks/train/video1_frame6950.json\n",
      "Generating dataset from: images_masks/train/video4_frame10500.json\n",
      "Generating dataset from: images_masks/train/video2_frame6360.json\n",
      "Generating dataset from: images_masks/train/video1_frame3050.json\n",
      "Generating dataset from: images_masks/train/video4_frame10620.json\n",
      "Generating dataset from: images_masks/train/video4_frame1320.json\n",
      "Generating dataset from: images_masks/train/video2_frame7200.json\n",
      "Generating dataset from: images_masks/train/video1_frame3600.json\n",
      "Generating dataset from: images_masks/train/video1_frame950.json\n",
      "Generating dataset from: images_masks/train/video2_frame2820.json\n",
      "Generating dataset from: images_masks/train/video6_frame10380.json\n",
      "Generating dataset from: images_masks/train/video2_frame7980.json\n",
      "Generating dataset from: images_masks/train/video1_frame3200.json\n",
      "Generating dataset from: images_masks/train/video2_frame1380.json\n",
      "Generating dataset from: images_masks/train/video2_frame9720.json\n",
      "Generating dataset from: images_masks/train/video1_frame8800.json\n",
      "Generating dataset from: images_masks/train/video2_frame4740.json\n",
      "Generating dataset from: images_masks/train/video1_frame8900.json\n",
      "Generating dataset from: images_masks/train/video2_frame2220.json\n",
      "Generating dataset from: images_masks/train/video1_frame9950.json\n",
      "Generating dataset from: images_masks/train/video2_frame3120.json\n",
      "Generating dataset from: images_masks/train/video2_frame4560.json\n",
      "Generating dataset from: images_masks/train/video1_frame4450.json\n",
      "Generating dataset from: images_masks/train/video1_frame4550.json\n",
      "Generating dataset from: images_masks/train/video1_frame8250.json\n",
      "Generating dataset from: images_masks/train/video1_frame4200.json\n",
      "Generating dataset from: images_masks/train/video1_frame7350.json\n",
      "Generating dataset from: images_masks/train/video1_frame7650.json\n",
      "Generating dataset from: images_masks/train/video1_frame1600.json\n",
      "Generating dataset from: images_masks/train/video1_frame7050.json\n",
      "Generating dataset from: images_masks/train/video1_frame3500.json\n",
      "Generating dataset from: images_masks/train/video2_frame1800.json\n",
      "Generating dataset from: images_masks/train/video1_frame8550.json\n",
      "Generating dataset from: images_masks/train/video6_frame10440.json\n",
      "Generating dataset from: images_masks/train/video2_frame1860.json\n",
      "Generating dataset from: images_masks/train/video2_frame2040.json\n",
      "Generating dataset from: images_masks/train/video1_frame10150.json\n",
      "Generating dataset from: images_masks/train/video1_frame4700.json\n",
      "Generating dataset from: images_masks/train/video1_frame3550.json\n",
      "Generating dataset from: images_masks/train/video2_frame7080.json\n",
      "Generating dataset from: images_masks/train/video1_frame1350.json\n",
      "Generating dataset from: images_masks/train/video3_frame10080.json\n",
      "Generating dataset from: images_masks/train/video3_frame10020.json\n",
      "Generating dataset from: images_masks/train/video1_frame7200.json\n",
      "Generating dataset from: images_masks/train/video2_frame5940.json\n",
      "Generating dataset from: images_masks/train/video1_frame2150.json\n",
      "Generating dataset from: images_masks/train/video1_frame1450.json\n",
      "Generating dataset from: images_masks/train/video2_frame3660.json\n",
      "Generating dataset from: images_masks/train/video4_frame1200.json\n",
      "Generating dataset from: images_masks/train/video2_frame8760.json\n",
      "Generating dataset from: images_masks/train/video1_frame9150.json\n",
      "Generating dataset from: images_masks/train/video2_frame3420.json\n",
      "Generating dataset from: images_masks/train/video1_frame9000.json\n",
      "Generating dataset from: images_masks/train/video1_frame4750.json\n",
      "Generating dataset from: images_masks/train/video2_frame6720.json\n",
      "Generating dataset from: images_masks/train/video1_frame1950.json\n",
      "Generating dataset from: images_masks/train/video1_frame3150.json\n",
      "Generating dataset from: images_masks/train/video4_frame10140.json\n",
      "Generating dataset from: images_masks/train/video2_frame8700.json\n",
      "Generating dataset from: images_masks/train/video1_frame2200.json\n",
      "Generating dataset from: images_masks/train/video3_frame10140.json\n",
      "Generating dataset from: images_masks/train/video1_frame1750.json\n",
      "Generating dataset from: images_masks/train/video1_frame7700.json\n",
      "Generating dataset from: images_masks/train/video1_frame5300.json\n",
      "Generating dataset from: images_masks/train/video1_frame7900.json\n",
      "Generating dataset from: images_masks/train/video2_frame5040.json\n",
      "Generating dataset from: images_masks/train/video1_frame1700.json\n",
      "Generating dataset from: images_masks/train/video2_frame7380.json\n",
      "Generating dataset from: images_masks/train/video2_frame5700.json\n",
      "Generating dataset from: images_masks/train/video2_frame4200.json\n",
      "Generating dataset from: images_masks/train/video4_frame10260.json\n",
      "Generating dataset from: images_masks/train/video1_frame7750.json\n",
      "Generating dataset from: images_masks/train/video1_frame5750.json\n",
      "Generating dataset from: images_masks/train/video2_frame4080.json\n",
      "Generating dataset from: images_masks/train/video1_frame7450.json\n",
      "Generating dataset from: images_masks/train/video2_frame2760.json\n",
      "Generating dataset from: images_masks/train/video1_frame1550.json\n",
      "Generating dataset from: images_masks/train/video2_frame3780.json\n",
      "Generating dataset from: images_masks/train/video1_frame9700.json\n",
      "Generating dataset from: images_masks/train/video2_frame2280.json\n",
      "Generating dataset from: images_masks/train/video2_frame3480.json\n",
      "Generating dataset from: images_masks/train/video2_frame4380.json\n",
      "Generating dataset from: images_masks/train/video1_frame2900.json\n",
      "Generating dataset from: images_masks/train/video2_frame2400.json\n",
      "Generating dataset from: images_masks/train/video1_frame9850.json\n",
      "Generating dataset from: images_masks/train/video2_frame6540.json\n",
      "Generating dataset from: images_masks/train/video1_frame1100.json\n",
      "Generating dataset from: images_masks/train/video3_frame10440.json\n",
      "Generating dataset from: images_masks/train/video1_frame3250.json\n",
      "Generating dataset from: images_masks/train/video2_frame6660.json\n",
      "Generating dataset from: images_masks/train/video1_frame9200.json\n",
      "Generating dataset from: images_masks/train/video1_frame4100.json\n",
      "Generating dataset from: images_masks/train/video2_frame7680.json\n",
      "Generating dataset from: images_masks/train/video1_frame1250.json\n",
      "Generating dataset from: images_masks/train/video1_frame5200.json\n",
      "Generating dataset from: images_masks/train/video1_frame5150.json\n",
      "Generating dataset from: images_masks/train/video1_frame1650.json\n",
      "Generating dataset from: images_masks/train/video1_frame8850.json\n",
      "Generating dataset from: images_masks/train/video2_frame4320.json\n",
      "Generating dataset from: images_masks/train/video1_frame2000.json\n",
      "Creating dataset: images_masks/test/coco\n",
      "Generating dataset from: images_masks/test/video2_frame8940.json\n",
      "Generating dataset from: images_masks/test/video6_frame10080.json\n",
      "Generating dataset from: images_masks/test/video1_frame1000.json\n",
      "Generating dataset from: images_masks/test/video1_frame3950.json\n",
      "Generating dataset from: images_masks/test/video2_frame5820.json\n",
      "Generating dataset from: images_masks/test/video1_frame3400.json\n",
      "Generating dataset from: images_masks/test/video1_frame7550.json\n",
      "Generating dataset from: images_masks/test/video1_frame1400.json\n",
      "Generating dataset from: images_masks/test/video4_frame10020.json\n",
      "Generating dataset from: images_masks/test/video6_frame10200.json\n",
      "Generating dataset from: images_masks/test/video1_frame4250.json\n",
      "Generating dataset from: images_masks/test/video1_frame8700.json\n",
      "Generating dataset from: images_masks/test/video2_frame5880.json\n",
      "Generating dataset from: images_masks/test/video4_frame1020.json\n",
      "Generating dataset from: images_masks/test/video1_frame9550.json\n",
      "Generating dataset from: images_masks/test/video2_frame8220.json\n",
      "Generating dataset from: images_masks/test/video1_frame5500.json\n",
      "Generating dataset from: images_masks/test/video2_frame7560.json\n",
      "Generating dataset from: images_masks/test/video2_frame3240.json\n",
      "Generating dataset from: images_masks/test/video2_frame8460.json\n",
      "Generating dataset from: images_masks/test/video2_frame2640.json\n",
      "Generating dataset from: images_masks/test/video2_frame4620.json\n",
      "Generating dataset from: images_masks/test/video1_frame2300.json\n",
      "Generating dataset from: images_masks/test/video4_frame10440.json\n",
      "Generating dataset from: images_masks/test/video2_frame7320.json\n",
      "Generating dataset from: images_masks/test/video1_frame9650.json\n",
      "Generating dataset from: images_masks/test/video3_frame10380.json\n",
      "Generating dataset from: images_masks/test/video2_frame6180.json\n",
      "Generating dataset from: images_masks/test/video1_frame3700.json\n",
      "Generating dataset from: images_masks/test/video1_frame4300.json\n",
      "Generating dataset from: images_masks/test/video1_frame3300.json\n",
      "Generating dataset from: images_masks/test/video1_frame2350.json\n",
      "Creating dataset: images_masks/val/coco\n",
      "Generating dataset from: images_masks/val/video2_frame5220.json\n",
      "Generating dataset from: images_masks/val/video1_frame2450.json\n",
      "Generating dataset from: images_masks/val/video2_frame1680.json\n",
      "Generating dataset from: images_masks/val/video2_frame8820.json\n",
      "Generating dataset from: images_masks/val/video2_frame1920.json\n",
      "Generating dataset from: images_masks/val/video2_frame4920.json\n",
      "Generating dataset from: images_masks/val/video2_frame3900.json\n",
      "Generating dataset from: images_masks/val/video2_frame5400.json\n",
      "Generating dataset from: images_masks/val/video1_frame1050.json\n",
      "Generating dataset from: images_masks/val/video3_frame1020.json\n",
      "Generating dataset from: images_masks/val/video1_frame8100.json\n",
      "Generating dataset from: images_masks/val/video2_frame5340.json\n",
      "Generating dataset from: images_masks/val/video1_frame5800.json\n",
      "Generating dataset from: images_masks/val/video2_frame3060.json\n",
      "Generating dataset from: images_masks/val/video1_frame3450.json\n",
      "Generating dataset from: images_masks/val/video1_frame2750.json\n",
      "Generating dataset from: images_masks/val/video1_frame4150.json\n",
      "Generating dataset from: images_masks/val/video2_frame6480.json\n",
      "Generating dataset from: images_masks/val/video2_frame1260.json\n",
      "Generating dataset from: images_masks/val/video4_frame1080.json\n",
      "Generating dataset from: images_masks/val/video1_frame4950.json\n",
      "Generating dataset from: images_masks/val/video2_frame4680.json\n",
      "Generating dataset from: images_masks/val/video2_frame7260.json\n",
      "Generating dataset from: images_masks/val/video2_frame7800.json\n",
      "Generating dataset from: images_masks/val/video1_frame4800.json\n",
      "Generating dataset from: images_masks/val/video1_frame9250.json\n",
      "Generating dataset from: images_masks/val/video1_frame10000.json\n",
      "Generating dataset from: images_masks/val/video2_frame6840.json\n",
      "Generating dataset from: images_masks/val/video2_frame4980.json\n",
      "Generating dataset from: images_masks/val/video1_frame8050.json\n",
      "Generating dataset from: images_masks/val/video1_frame2650.json\n",
      "Generating dataset from: images_masks/val/video1_frame10200.json\n",
      "Generating dataset from: images_masks/val/video1_frame10250.json\n",
      "Generating dataset from: images_masks/val/video4_frame10200.json\n",
      "Generating dataset from: images_masks/val/video1_frame1300.json\n",
      "Generating dataset from: images_masks/val/video1_frame2700.json\n",
      "Generating dataset from: images_masks/val/video2_frame7920.json\n",
      "Generating dataset from: images_masks/val/video1_frame4400.json\n",
      "Generating dataset from: images_masks/val/video1_frame3100.json\n",
      "Generating dataset from: images_masks/val/video2_frame2520.json\n",
      "Generating dataset from: images_masks/val/video1_frame7400.json\n",
      "Generating dataset from: images_masks/val/video2_frame8520.json\n",
      "Generating dataset from: images_masks/val/video1_frame3850.json\n",
      "Generating dataset from: images_masks/val/video1_frame5550.json\n",
      "Generating dataset from: images_masks/val/video1_frame9900.json\n",
      "Generating dataset from: images_masks/val/video4_frame10380.json\n",
      "Generating dataset from: images_masks/val/video1_frame8450.json\n",
      "Generating dataset from: images_masks/val/video1_frame4050.json\n",
      "\u001b[34;42mimages_masks\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   └── \u001b[01;34mcoco\u001b[00m\n",
      "│       ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│       └── \u001b[01;34mVisualization\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   └── \u001b[01;34mcoco\u001b[00m\n",
      "│       ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│       └── \u001b[01;34mVisualization\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    └── \u001b[01;34mcoco\u001b[00m\n",
      "        ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "        └── \u001b[01;34mVisualization\u001b[00m\n",
      "\n",
      "12 directories\n"
     ]
    }
   ],
   "source": [
    "# vamos a convertir estas fotos en y anotaciones en datasets de formato COCO. Tenemos que hacerlo para los sets de train\n",
    "# test y validación. Tenemos que pasar como argumento archivo txt con los labels siguiendo el formato indiado en la\n",
    "# documentación oficial de labelme https://github.com/wkentaro/labelme/tree/master/examples/instance_segmentation. Un ejemplo\n",
    "# de cómo debe ser este archivo se muestra debajo\n",
    "!python3 scripts/labelme2coco.py {images_dir}/train {images_dir}/train/coco --labels {training_dir}/labels.txt\n",
    "!python3 scripts/labelme2coco.py {images_dir}/test {images_dir}/test/coco --labels {training_dir}/labels.txt\n",
    "!python3 scripts/labelme2coco.py {images_dir}/val {images_dir}/val/coco --labels {training_dir}/labels.txt\n",
    "!tree -d {images_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"labels_txt.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'images_masks/test/coco': Is a directory\n",
      "rm: cannot remove 'images_masks/train/coco': Is a directory\n",
      "rm: cannot remove 'images_masks/val/coco': Is a directory\n",
      "\u001b[34;42mimages_masks\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│   └── \u001b[01;34mVisualization\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│   └── \u001b[01;34mVisualization\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "    └── \u001b[01;34mVisualization\u001b[00m\n",
      "\n",
      "9 directories\n"
     ]
    }
   ],
   "source": [
    "# ahora borramos las imágenes y anotaciones de las carpetas train, test y val, ya que la carpeta coco dentro de cada \n",
    "# una de estas carpetas ya contiene las imágenes originales\n",
    "!rm {images_dir}/test/*\n",
    "!mv {images_dir}/test/coco/* {images_dir}/test\n",
    "!rm -rf {images_dir}/test/coco \n",
    "\n",
    "!rm {images_dir}/train/*\n",
    "!mv {images_dir}/train/coco/* {images_dir}/train\n",
    "!rm -rf {images_dir}/train/coco \n",
    "\n",
    "!rm {images_dir}/val/*\n",
    "!mv {images_dir}/val/coco/* {images_dir}/val\n",
    "!rm -rf {images_dir}/val/coco \n",
    "\n",
    "!tree -d {images_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0218 10:29:36.263575 139680152872768 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0218 10:29:36.263960 139680152872768 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0218 10:29:36.264113 139680152872768 create_coco_tf_record.py:441] On image 0 of 241\n",
      "I0218 10:29:50.924984 139680152872768 create_coco_tf_record.py:441] On image 100 of 241\n",
      "I0218 10:30:08.305954 139680152872768 create_coco_tf_record.py:441] On image 200 of 241\n",
      "I0218 10:30:15.042848 139680152872768 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n",
      "I0218 10:30:15.457366 139680152872768 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0218 10:30:15.457702 139680152872768 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0218 10:30:15.457803 139680152872768 create_coco_tf_record.py:441] On image 0 of 48\n",
      "I0218 10:30:22.786206 139680152872768 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n",
      "I0218 10:30:22.801609 139680152872768 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0218 10:30:22.801818 139680152872768 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0218 10:30:22.801902 139680152872768 create_coco_tf_record.py:441] On image 0 of 32\n",
      "I0218 10:30:28.072308 139680152872768 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n"
     ]
    }
   ],
   "source": [
    "# ahora tenemos que generar los tfrecords usando estos dataset en formato coco\n",
    "!python3 models/research/object_detection/dataset_tools/create_coco_tf_record.py --logtostderr \\\n",
    "--train_image_dir={images_dir}/train \\\n",
    "--val_image_dir={images_dir}/val \\\n",
    "--test_image_dir={images_dir}/test \\\n",
    "--train_annotations_file={images_dir}/train/annotations.json \\\n",
    "--val_annotations_file={images_dir}/val/annotations.json \\\n",
    "--testdev_annotations_file={images_dir}/test/annotations.json \\\n",
    "--output_dir={training_dir}/tfrecord \\\n",
    "--include_masks=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_map.pbtxt  mask_rcnn_inception_v2_coco.config  tfrecord\r\n",
      "labels.txt\t temp.config\r\n"
     ]
    }
   ],
   "source": [
    "!ls {training_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta celda se debe correr para crear un archivo de configuración temporal a partir de un archivo de configuración genérico incluído en los samples de la API de detección de objetos. Funcionará en muchos casos, pero es posible que en algunos casos sea necesario modificar este archivo a mano. Si se desean editar campos adicionales como el larning rate, el batch_size o la estructura de la red, se deberá modificar directamente el archivo de configuración mo editar la celda de debajo para añadir estas modificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_files= glob.glob(training_dir+\"/tfrecord/coco_val.record*\")[0].split(os.sep)[-1].split(\"-\")[-1]\n",
    "num_train_files= glob.glob(training_dir+\"/tfrecord/coco_train.record*\")[0].split(os.sep)[-1].split(\"-\")[-1]\n",
    "!sed 's#num_classes:.*#num_classes: {n_classes}#' {training_dir}/{config_file_name} >{training_dir}/temp.config\n",
    "!sed -i 's#PATH_TO_BE_CONFIGURED#{training_dir}#' {training_dir}/temp.config\n",
    "!sed -i 's#mscoco_label_map.pbtxt#label_map.pbtxt#' {training_dir}/temp.config\n",
    "!sed -i 's#mscoco_val.*#tfrecord/coco_val.record-?????-of-{num_val_files}\"#' {training_dir}/temp.config\n",
    "!sed -i 's#mscoco_train.*#tfrecord/coco_train.record-?????-of-{num_train_files}\"#' {training_dir}/temp.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Mask R-CNN with Inception V2\r\n",
      "# Configured for MSCOCO Dataset.\r\n",
      "# Users should configure the fine_tune_checkpoint field in the train config as\r\n",
      "# well as the label_map_path and input_path fields in the train_input_reader and\r\n",
      "# eval_input_reader. Search for \"training_masks\" to find the fields that\r\n",
      "# should be configured.\r\n",
      "\r\n",
      "model {\r\n",
      "  faster_rcnn {\r\n",
      "    num_classes: 4\r\n",
      "    image_resizer {\r\n",
      "      keep_aspect_ratio_resizer {\r\n",
      "        min_dimension: 800\r\n",
      "        max_dimension: 1365\r\n",
      "      }\r\n",
      "    }\r\n",
      "    number_of_stages: 3\r\n",
      "    feature_extractor {\r\n",
      "      type: 'faster_rcnn_inception_v2'\r\n",
      "      first_stage_features_stride: 16\r\n",
      "    }\r\n",
      "    first_stage_anchor_generator {\r\n",
      "      grid_anchor_generator {\r\n",
      "        scales: [0.25, 0.5, 1.0, 2.0]\r\n",
      "        aspect_ratios: [0.5, 1.0, 2.0]\r\n",
      "        height_stride: 16\r\n",
      "        width_stride: 16\r\n",
      "      }\r\n",
      "    }\r\n",
      "    first_stage_box_predictor_conv_hyperparams {\r\n",
      "      op: CONV\r\n",
      "      regularizer {\r\n",
      "        l2_regularizer {\r\n",
      "          weight: 0.0\r\n",
      "        }\r\n",
      "      }\r\n",
      "      initializer {\r\n",
      "        truncated_normal_initializer {\r\n",
      "          stddev: 0.01\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    first_stage_nms_score_threshold: 0.0\r\n",
      "    first_stage_nms_iou_threshold: 0.7\r\n",
      "    first_stage_max_proposals: 300\r\n",
      "    first_stage_localization_loss_weight: 2.0\r\n",
      "    first_stage_objectness_loss_weight: 1.0\r\n",
      "    initial_crop_size: 14\r\n",
      "    maxpool_kernel_size: 2\r\n",
      "    maxpool_stride: 2\r\n",
      "    second_stage_box_predictor {\r\n",
      "      mask_rcnn_box_predictor {\r\n",
      "        use_dropout: false\r\n",
      "        dropout_keep_probability: 1.0\r\n",
      "        predict_instance_masks: true\r\n",
      "        mask_height: 15\r\n",
      "        mask_width: 15\r\n",
      "        mask_prediction_conv_depth: 0\r\n",
      "        mask_prediction_num_conv_layers: 2\r\n",
      "        fc_hyperparams {\r\n",
      "          op: FC\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            variance_scaling_initializer {\r\n",
      "              factor: 1.0\r\n",
      "              uniform: true\r\n",
      "              mode: FAN_AVG\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "        conv_hyperparams {\r\n",
      "          op: CONV\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            truncated_normal_initializer {\r\n",
      "              stddev: 0.01\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    second_stage_post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 0.0\r\n",
      "        iou_threshold: 0.6\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 300\r\n",
      "      }\r\n",
      "      score_converter: SOFTMAX\r\n",
      "    }\r\n",
      "    second_stage_localization_loss_weight: 2.0\r\n",
      "    second_stage_classification_loss_weight: 1.0\r\n",
      "    second_stage_mask_prediction_loss_weight: 4.0\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_config: {\r\n",
      "  batch_size: 1\r\n",
      "  optimizer {\r\n",
      "    momentum_optimizer: {\r\n",
      "      learning_rate: {\r\n",
      "        manual_step_learning_rate {\r\n",
      "          initial_learning_rate: 0.0002\r\n",
      "          schedule {\r\n",
      "            step: 900000\r\n",
      "            learning_rate: .00002\r\n",
      "          }\r\n",
      "          schedule {\r\n",
      "            step: 1200000\r\n",
      "            learning_rate: .000002\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.9\r\n",
      "    }\r\n",
      "    use_moving_average: false\r\n",
      "  }\r\n",
      "  gradient_clipping_by_norm: 10.0\r\n",
      "  fine_tune_checkpoint: \"training_masks/model.ckpt\"\r\n",
      "  from_detection_checkpoint: true\r\n",
      "  # Note: The below line limits the training process to 200K steps, which we\r\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\r\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\r\n",
      "  # never decay). Remove the below line to train indefinitely.\r\n",
      "  num_steps: 200000\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"training_masks/tfrecord/coco_train.record-?????-of-00100\"\r\n",
      "  }\r\n",
      "  label_map_path: \"training_masks/label_map.pbtxt\"\r\n",
      "  load_instance_masks: true\r\n",
      "  mask_type: PNG_MASKS\r\n",
      "}\r\n",
      "\r\n",
      "eval_config: {\r\n",
      "  num_examples: 8000\r\n",
      "  # Note: The below line limits the evaluation process to 10 evaluations.\r\n",
      "  # Remove the below line to evaluate indefinitely.\r\n",
      "  max_evals: 10\r\n",
      "}\r\n",
      "\r\n",
      "eval_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"training_masks/tfrecord/coco_val.record-?????-of-00050\"\r\n",
      "  }\r\n",
      "  label_map_path: \"training_masks/label_map.pbtxt\"\r\n",
      "  load_instance_masks: true\r\n",
      "  mask_type: PNG_MASKS\r\n",
      "  shuffle: false\r\n",
      "  num_readers: 1\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat {training_dir}/temp.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y exportación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'training_masks/eval_0': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# borramos los archivos de un entrenamiento anterior si es que queremos empezar de nuevo en vez de reanudarlo\n",
    "!rm {training_dir}/checkpoint\\\n",
    "{training_dir}/events*\\\n",
    "{training_dir}/graph.pbtxt\\\n",
    "{training_dir}/model*\n",
    "!rm -r {training_dir}/eval_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0218 10:33:10.442061 139942329120576 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 1000000\n",
      "I0218 10:33:10.442294 139942329120576 config_util.py:552] Maybe overwriting train_steps: 1000000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0218 10:33:10.442344 139942329120576 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0218 10:33:10.442383 139942329120576 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0218 10:33:10.442425 139942329120576 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0218 10:33:10.442478 139942329120576 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "I0218 10:33:10.442523 139942329120576 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training_masks/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f464bffa510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0218 10:33:10.442813 139942329120576 estimator.py:212] Using config: {'_model_dir': 'training_masks/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f464bffa510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f464bfea7a0>) includes params argument, but params are not passed to Estimator.\n",
      "W0218 10:33:10.443016 139942329120576 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f464bfea7a0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0218 10:33:10.443238 139942329120576 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0218 10:33:10.443334 139942329120576 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0218 10:33:10.443458 139942329120576 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0218 10:33:10.446863 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['training_masks/tfrecord/coco_train.record-?????-of-00100']\n",
      "I0218 10:33:10.461674 139942329120576 dataset_builder.py:148] Reading unweighted datasets: ['training_masks/tfrecord/coco_train.record-?????-of-00100']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['training_masks/tfrecord/coco_train.record-?????-of-00100']\n",
      "I0218 10:33:10.463180 139942329120576 dataset_builder.py:77] Reading record datasets for input file: ['training_masks/tfrecord/coco_train.record-?????-of-00100']\n",
      "INFO:tensorflow:Number of filenames to read: 100\n",
      "I0218 10:33:10.463247 139942329120576 dataset_builder.py:78] Number of filenames to read: 100\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0218 10:33:10.466744 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0218 10:33:10.481438 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/inputs.py:91: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0218 10:33:18.261460 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/inputs.py:91: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0218 10:33:18.348087 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0218 10:33:21.738434 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0218 10:33:24.513538 139942329120576 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0218 10:33:24.538169 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:33:25.446009 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:33:25.535007 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0218 10:33:25.535246 139942329120576 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0218 10:33:26.024406 139942329120576 deprecation.py:506] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0218 10:33:26.345583 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:33:26.347054 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:33:26.357525 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:33:26.372948 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0218 10:33:26.589794 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "/home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0218 10:33:29.351169 139942329120576 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0218 10:33:29.352049 139942329120576 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0218 10:33:30.669890 139942329120576 monitored_session.py:240] Graph was finalized.\n",
      "2021-02-18 10:33:30.670173: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-02-18 10:33:30.694027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3799900000 Hz\n",
      "2021-02-18 10:33:30.695194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b332e99060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-18 10:33:30.695242: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-02-18 10:33:30.699195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-02-18 10:33:30.941782: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b332fb61c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-18 10:33:30.941848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2021-02-18 10:33:30.941867: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080, Compute Capability 6.1\n",
      "2021-02-18 10:33:30.947734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2021-02-18 10:33:30.948802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2021-02-18 10:33:30.949273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:33:30.951383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-02-18 10:33:30.953315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-02-18 10:33:30.953930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-02-18 10:33:30.956391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-02-18 10:33:30.958310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-02-18 10:33:30.963001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-02-18 10:33:30.968571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2021-02-18 10:33:30.968657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:33:30.970766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-02-18 10:33:30.970789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2021-02-18 10:33:30.970798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2021-02-18 10:33:30.970805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2021-02-18 10:33:30.972690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7414 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2021-02-18 10:33:30.976390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7611 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0218 10:33:33.258130 139942329120576 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0218 10:33:33.454662 139942329120576 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training_masks/model.ckpt.\n",
      "I0218 10:33:37.326764 139942329120576 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training_masks/model.ckpt.\n",
      "2021-02-18 10:33:41.932989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-02-18 10:33:45.335966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-02-18 10:33:46.369449: W tensorflow/stream_executor/cuda/ptxas_utils.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.\n",
      "INFO:tensorflow:loss = 4.150903, step = 0\n",
      "I0218 10:33:49.031097 139942329120576 basic_session_run_hooks.py:262] loss = 4.150903, step = 0\n",
      "INFO:tensorflow:global_step/sec: 4.29351\n",
      "I0218 10:34:12.320978 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.29351\n",
      "INFO:tensorflow:loss = 2.9682136, step = 100 (23.296 sec)\n",
      "I0218 10:34:12.326985 139942329120576 basic_session_run_hooks.py:260] loss = 2.9682136, step = 100 (23.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.79298\n",
      "I0218 10:34:33.184910 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.79298\n",
      "INFO:tensorflow:loss = 4.579813, step = 200 (20.859 sec)\n",
      "I0218 10:34:33.186098 139942329120576 basic_session_run_hooks.py:260] loss = 4.579813, step = 200 (20.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.78068\n",
      "I0218 10:34:54.102423 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.78068\n",
      "INFO:tensorflow:loss = 4.9410486, step = 300 (20.918 sec)\n",
      "I0218 10:34:54.103676 139942329120576 basic_session_run_hooks.py:260] loss = 4.9410486, step = 300 (20.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.76429\n",
      "I0218 10:35:15.091890 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.76429\n",
      "INFO:tensorflow:loss = 4.25979, step = 400 (20.989 sec)\n",
      "I0218 10:35:15.093087 139942329120576 basic_session_run_hooks.py:260] loss = 4.25979, step = 400 (20.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.68363\n",
      "I0218 10:35:36.442873 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.68363\n",
      "INFO:tensorflow:loss = 3.0730119, step = 500 (21.351 sec)\n",
      "I0218 10:35:36.444298 139942329120576 basic_session_run_hooks.py:260] loss = 3.0730119, step = 500 (21.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.77926\n",
      "I0218 10:35:57.366604 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.77926\n",
      "INFO:tensorflow:loss = 3.1218395, step = 600 (20.924 sec)\n",
      "I0218 10:35:57.367813 139942329120576 basic_session_run_hooks.py:260] loss = 3.1218395, step = 600 (20.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.76503\n",
      "I0218 10:36:18.352804 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.76503\n",
      "INFO:tensorflow:loss = 4.6154356, step = 700 (20.986 sec)\n",
      "I0218 10:36:18.353836 139942329120576 basic_session_run_hooks.py:260] loss = 4.6154356, step = 700 (20.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.72106\n",
      "I0218 10:36:39.534518 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.72106\n",
      "INFO:tensorflow:loss = 4.342367, step = 800 (21.182 sec)\n",
      "I0218 10:36:39.535578 139942329120576 basic_session_run_hooks.py:260] loss = 4.342367, step = 800 (21.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.70946\n",
      "I0218 10:37:00.768345 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.70946\n",
      "INFO:tensorflow:loss = 4.296096, step = 900 (21.234 sec)\n",
      "I0218 10:37:00.769423 139942329120576 basic_session_run_hooks.py:260] loss = 4.296096, step = 900 (21.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.72638\n",
      "I0218 10:37:21.926240 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.72638\n",
      "INFO:tensorflow:loss = 4.2372184, step = 1000 (21.158 sec)\n",
      "I0218 10:37:21.927515 139942329120576 basic_session_run_hooks.py:260] loss = 4.2372184, step = 1000 (21.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.70563\n",
      "I0218 10:37:43.177302 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.70563\n",
      "INFO:tensorflow:loss = 3.339772, step = 1100 (21.251 sec)\n",
      "I0218 10:37:43.178140 139942329120576 basic_session_run_hooks.py:260] loss = 3.339772, step = 1100 (21.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.69454\n",
      "I0218 10:38:04.478753 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.69454\n",
      "INFO:tensorflow:loss = 3.5514748, step = 1200 (21.302 sec)\n",
      "I0218 10:38:04.479862 139942329120576 basic_session_run_hooks.py:260] loss = 3.5514748, step = 1200 (21.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73173\n",
      "I0218 10:38:25.612683 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.73173\n",
      "INFO:tensorflow:loss = 4.073802, step = 1300 (21.134 sec)\n",
      "I0218 10:38:25.613964 139942329120576 basic_session_run_hooks.py:260] loss = 4.073802, step = 1300 (21.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.77639\n",
      "I0218 10:38:46.549007 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.77639\n",
      "INFO:tensorflow:loss = 4.637054, step = 1400 (20.936 sec)\n",
      "I0218 10:38:46.550253 139942329120576 basic_session_run_hooks.py:260] loss = 4.637054, step = 1400 (20.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.68725\n",
      "I0218 10:39:07.883479 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.68725\n",
      "INFO:tensorflow:loss = 1.7246557, step = 1500 (21.334 sec)\n",
      "I0218 10:39:07.884611 139942329120576 basic_session_run_hooks.py:260] loss = 1.7246557, step = 1500 (21.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.72777\n",
      "I0218 10:39:29.035094 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.72777\n",
      "INFO:tensorflow:loss = 3.494997, step = 1600 (21.152 sec)\n",
      "I0218 10:39:29.036339 139942329120576 basic_session_run_hooks.py:260] loss = 3.494997, step = 1600 (21.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.72858\n",
      "I0218 10:39:50.183115 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.72858\n",
      "INFO:tensorflow:loss = 4.3909855, step = 1700 (21.148 sec)\n",
      "I0218 10:39:50.184410 139942329120576 basic_session_run_hooks.py:260] loss = 4.3909855, step = 1700 (21.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73284\n",
      "I0218 10:40:11.312005 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.73284\n",
      "INFO:tensorflow:loss = 5.1859446, step = 1800 (21.129 sec)\n",
      "I0218 10:40:11.312912 139942329120576 basic_session_run_hooks.py:260] loss = 5.1859446, step = 1800 (21.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.67482\n",
      "I0218 10:40:32.703270 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.67482\n",
      "INFO:tensorflow:loss = 0.59811103, step = 1900 (21.392 sec)\n",
      "I0218 10:40:32.704514 139942329120576 basic_session_run_hooks.py:260] loss = 0.59811103, step = 1900 (21.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.68234\n",
      "I0218 10:40:54.060133 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.68234\n",
      "INFO:tensorflow:loss = 4.0471067, step = 2000 (21.357 sec)\n",
      "I0218 10:40:54.061539 139942329120576 basic_session_run_hooks.py:260] loss = 4.0471067, step = 2000 (21.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73822\n",
      "I0218 10:41:15.165085 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.73822\n",
      "INFO:tensorflow:loss = 3.6967437, step = 2100 (21.105 sec)\n",
      "I0218 10:41:15.166374 139942329120576 basic_session_run_hooks.py:260] loss = 3.6967437, step = 2100 (21.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.65752\n",
      "I0218 10:41:36.635714 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.65752\n",
      "INFO:tensorflow:loss = 2.030884, step = 2200 (21.470 sec)\n",
      "I0218 10:41:36.636839 139942329120576 basic_session_run_hooks.py:260] loss = 2.030884, step = 2200 (21.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.7061\n",
      "I0218 10:41:57.884728 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.7061\n",
      "INFO:tensorflow:loss = 3.7862637, step = 2300 (21.249 sec)\n",
      "I0218 10:41:57.886004 139942329120576 basic_session_run_hooks.py:260] loss = 3.7862637, step = 2300 (21.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.66955\n",
      "I0218 10:42:19.300068 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.66955\n",
      "INFO:tensorflow:loss = 2.0785618, step = 2400 (21.415 sec)\n",
      "I0218 10:42:19.301301 139942329120576 basic_session_run_hooks.py:260] loss = 2.0785618, step = 2400 (21.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.70846\n",
      "I0218 10:42:40.538415 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.70846\n",
      "INFO:tensorflow:loss = 1.782286, step = 2500 (21.238 sec)\n",
      "I0218 10:42:40.539436 139942329120576 basic_session_run_hooks.py:260] loss = 1.782286, step = 2500 (21.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.64305\n",
      "I0218 10:43:02.075981 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.64305\n",
      "INFO:tensorflow:loss = 1.3870534, step = 2600 (21.538 sec)\n",
      "I0218 10:43:02.077241 139942329120576 basic_session_run_hooks.py:260] loss = 1.3870534, step = 2600 (21.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.63213\n",
      "I0218 10:43:23.664243 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.63213\n",
      "INFO:tensorflow:loss = 2.9246206, step = 2700 (21.588 sec)\n",
      "I0218 10:43:23.664944 139942329120576 basic_session_run_hooks.py:260] loss = 2.9246206, step = 2700 (21.588 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2772 into training_masks/model.ckpt.\n",
      "I0218 10:43:38.791898 139942329120576 basic_session_run_hooks.py:606] Saving checkpoints for 2772 into training_masks/model.ckpt.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['training_masks/tfrecord/coco_val.record-?????-of-00050']\n",
      "I0218 10:43:39.399665 139942329120576 dataset_builder.py:148] Reading unweighted datasets: ['training_masks/tfrecord/coco_val.record-?????-of-00050']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['training_masks/tfrecord/coco_val.record-?????-of-00050']\n",
      "I0218 10:43:39.401121 139942329120576 dataset_builder.py:77] Reading record datasets for input file: ['training_masks/tfrecord/coco_val.record-?????-of-00050']\n",
      "INFO:tensorflow:Number of filenames to read: 50\n",
      "I0218 10:43:39.401205 139942329120576 dataset_builder.py:78] Number of filenames to read: 50\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0218 10:43:40.140203 139942329120576 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:43:41.132166 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:43:41.221016 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0218 10:43:41.221257 139942329120576 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:43:41.842006 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:43:41.852311 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "W0218 10:43:42.164563 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:43:42.328439 139942329120576 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Removing rpn_box_predictor_features from prediction_dict\n",
      "I0218 10:43:42.355473 139942329120576 faster_rcnn_meta_arch.py:1565] Removing rpn_box_predictor_features from prediction_dict\n",
      "INFO:tensorflow:Removing rpn_features_to_crop from prediction_dict\n",
      "I0218 10:43:42.355570 139942329120576 faster_rcnn_meta_arch.py:1565] Removing rpn_features_to_crop from prediction_dict\n",
      "INFO:tensorflow:Removing feature_maps from prediction_dict\n",
      "I0218 10:43:42.355623 139942329120576 faster_rcnn_meta_arch.py:1565] Removing feature_maps from prediction_dict\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/eval_util.py:879: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0218 10:43:42.928256 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/eval_util.py:879: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0218 10:43:43.096024 139942329120576 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0218 10:43:43.448285 139942329120576 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-18T10:43:43Z\n",
      "I0218 10:43:43.458615 139942329120576 evaluation.py:255] Starting evaluation at 2021-02-18T10:43:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0218 10:43:43.740861 139942329120576 monitored_session.py:240] Graph was finalized.\n",
      "2021-02-18 10:43:43.742011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2021-02-18 10:43:43.742612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2021-02-18 10:43:43.742660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:43:43.742670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-02-18 10:43:43.742679: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-02-18 10:43:43.742688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-02-18 10:43:43.742697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-02-18 10:43:43.742706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-02-18 10:43:43.742716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-02-18 10:43:43.744299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2021-02-18 10:43:43.744346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-02-18 10:43:43.744352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2021-02-18 10:43:43.744358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2021-02-18 10:43:43.744363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2021-02-18 10:43:43.745435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7414 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2021-02-18 10:43:43.746006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7611 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from training_masks/model.ckpt-2772\n",
      "I0218 10:43:43.747051 139942329120576 saver.py:1284] Restoring parameters from training_masks/model.ckpt-2772\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0218 10:43:44.858298 139942329120576 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0218 10:43:45.012728 139942329120576 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 48 images.\n",
      "I0218 10:45:00.047989 139933482198784 coco_evaluation.py:282] Performing evaluation on 48 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0218 10:45:00.076499 139933482198784 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.01s)\n",
      "I0218 10:45:00.089269 139933482198784 coco_tools.py:138] DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-18-10:45:01\n",
      "I0218 10:45:01.057673 139942329120576 evaluation.py:275] Finished evaluation at 2021-02-18-10:45:01\n",
      "INFO:tensorflow:Saving dict for global step 2772: DetectionBoxes_Precision/mAP = 0.01156869, DetectionBoxes_Precision/mAP (large) = 0.027695071, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.03670361, DetectionBoxes_Precision/mAP@.75IOU = 0.004260122, DetectionBoxes_Recall/AR@1 = 0.011420964, DetectionBoxes_Recall/AR@10 = 0.0386456, DetectionBoxes_Recall/AR@100 = 0.08493437, DetectionBoxes_Recall/AR@100 (large) = 0.18992132, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/BoxClassifierLoss/classification_loss = 0.39947024, Loss/BoxClassifierLoss/localization_loss = 0.29718605, Loss/BoxClassifierLoss/mask_loss = 1.9491838, Loss/RPNLoss/localization_loss = 0.7414913, Loss/RPNLoss/objectness_loss = 0.49320626, Loss/total_loss = 3.8805387, global_step = 2772, learning_rate = 0.0002, loss = 3.8805387\n",
      "I0218 10:45:01.057909 139942329120576 estimator.py:2049] Saving dict for global step 2772: DetectionBoxes_Precision/mAP = 0.01156869, DetectionBoxes_Precision/mAP (large) = 0.027695071, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.03670361, DetectionBoxes_Precision/mAP@.75IOU = 0.004260122, DetectionBoxes_Recall/AR@1 = 0.011420964, DetectionBoxes_Recall/AR@10 = 0.0386456, DetectionBoxes_Recall/AR@100 = 0.08493437, DetectionBoxes_Recall/AR@100 (large) = 0.18992132, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/BoxClassifierLoss/classification_loss = 0.39947024, Loss/BoxClassifierLoss/localization_loss = 0.29718605, Loss/BoxClassifierLoss/mask_loss = 1.9491838, Loss/RPNLoss/localization_loss = 0.7414913, Loss/RPNLoss/objectness_loss = 0.49320626, Loss/total_loss = 3.8805387, global_step = 2772, learning_rate = 0.0002, loss = 3.8805387\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2772: training_masks/model.ckpt-2772\n",
      "I0218 10:45:01.746526 139942329120576 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2772: training_masks/model.ckpt-2772\n",
      "INFO:tensorflow:global_step/sec: 0.959557\n",
      "I0218 10:45:07.879099 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 0.959557\n",
      "INFO:tensorflow:loss = 4.237514, step = 2800 (104.216 sec)\n",
      "I0218 10:45:07.880547 139942329120576 basic_session_run_hooks.py:260] loss = 4.237514, step = 2800 (104.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.75822\n",
      "I0218 10:45:28.895397 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.75822\n",
      "INFO:tensorflow:loss = 3.8108706, step = 2900 (21.016 sec)\n",
      "I0218 10:45:28.896686 139942329120576 basic_session_run_hooks.py:260] loss = 3.8108706, step = 2900 (21.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73636\n",
      "I0218 10:45:50.008534 139942329120576 basic_session_run_hooks.py:692] global_step/sec: 4.73636\n",
      "INFO:tensorflow:loss = 4.1059303, step = 3000 (21.113 sec)\n",
      "I0218 10:45:50.009265 139942329120576 basic_session_run_hooks.py:260] loss = 4.1059303, step = 3000 (21.113 sec)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# entrenamos el modelo usando estos tfrecords. El modelo resultante se guardará el carpeta training_bb\n",
    "!python3 models/research/object_detection/model_main.py --alsologtostderr \\\n",
    "--model_dir={training_dir}/ \\\n",
    "--pipeline_config_path={training_dir}/temp.config \\\n",
    "--num_train_steps=1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# para correr el entrenamiento en la consola, copiar y pegar este comando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_dir=training_bb\n",
    "python3 models/research/object_detection/model_main.py --alsologtostderr \\\n",
    "--model_dir=$training_dir/ \\\n",
    "--pipeline_config_path=$training_dir/faster_rcnn_inception_v2_coco.config \\\n",
    "--num_train_steps=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En checkpoint más moderno es: \n",
      "training_masks/model.ckpt-2772\n"
     ]
    }
   ],
   "source": [
    "# corriendo esta celda sabremos cuál es el checkpoint más moderno\n",
    "import glob\n",
    "import os\n",
    "max_step=0\n",
    "for file in glob.glob(training_dir+\"/*\"):\n",
    "    if (\"model.ckpt\" in  file):\n",
    "        step=int (file.split(os.sep)[1].split(\".\")[1].split(\"-\")[1])\n",
    "        max_step= step if step>max_step else max_step\n",
    "        model_checkpoint_prefix=\"model.ckpt-{}\".format(max_step)\n",
    "print(\"En checkpoint más moderno es: \\n{}/model.ckpt-\".format(training_dir)+str(max_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0218 10:52:02.314922 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:52:03.126022 140447977408320 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:52:03.216019 140447977408320 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0218 10:52:03.216286 140447977408320 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0218 10:52:03.254338 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0218 10:52:03.609041 140447977408320 deprecation.py:506] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0218 10:52:03.930611 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:52:03.934094 140447977408320 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:52:03.946390 140447977408320 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "W0218 10:52:04.448543 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0218 10:52:04.645277 140447977408320 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Removing rpn_box_predictor_features from prediction_dict\n",
      "I0218 10:52:04.671555 140447977408320 faster_rcnn_meta_arch.py:1565] Removing rpn_box_predictor_features from prediction_dict\n",
      "INFO:tensorflow:Removing rpn_features_to_crop from prediction_dict\n",
      "I0218 10:52:04.671675 140447977408320 faster_rcnn_meta_arch.py:1565] Removing rpn_features_to_crop from prediction_dict\n",
      "INFO:tensorflow:Removing feature_maps from prediction_dict\n",
      "I0218 10:52:04.671713 140447977408320 faster_rcnn_meta_arch.py:1565] Removing feature_maps from prediction_dict\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0218 10:52:04.674322 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W0218 10:52:04.676275 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W0218 10:52:04.676995 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "242 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/13.15m params)\n",
      "  Conv (--/2.65m params)\n",
      "    Conv/biases (512, 512/512 params)\n",
      "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
      "  FirstStageBoxPredictor (--/36.94k params)\n",
      "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
      "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "  FirstStageFeatureExtractor (--/4.25m params)\n",
      "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "  SecondStageBoxPredictor (--/317.62k params)\n",
      "    SecondStageBoxPredictor/BoxEncodingPredictor (--/16.40k params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (16, 16/16 params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x16, 16.38k/16.38k params)\n",
      "    SecondStageBoxPredictor/ClassPredictor (--/5.12k params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/biases (5, 5/5 params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/weights (1024x5, 5.12k/5.12k params)\n",
      "    SecondStageBoxPredictor/Conv (--/294.94k params)\n",
      "      SecondStageBoxPredictor/Conv/biases (32, 32/32 params)\n",
      "      SecondStageBoxPredictor/Conv/weights (3x3x1024x32, 294.91k/294.91k params)\n",
      "    SecondStageBoxPredictor/Conv_1 (--/1.16k params)\n",
      "      SecondStageBoxPredictor/Conv_1/biases (4, 4/4 params)\n",
      "      SecondStageBoxPredictor/Conv_1/weights (3x3x32x4, 1.15k/1.15k params)\n",
      "  SecondStageFeatureExtractor (--/5.89m params)\n",
      "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
      "\n",
      "======================End of Report==========================\n",
      "242 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.17k flops)\n",
      "  map_3/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  map_2/while/mul (300/300 flops)\n",
      "  map_2/while/mul_1 (300/300 flops)\n",
      "  map_2/while/mul_2 (300/300 flops)\n",
      "  map_2/while/mul_3 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Maximum (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
      "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
      "  GridAnchorGenerator/truediv (12/12 flops)\n",
      "  GridAnchorGenerator/mul (12/12 flops)\n",
      "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
      "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  mul_1 (1/1 flops)\n",
      "  mul (1/1 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map_3/while/Less_1 (1/1 flops)\n",
      "  map_3/while/Less (1/1 flops)\n",
      "  map_2/while/Less_1 (1/1 flops)\n",
      "  map_2/while/Less (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map_1/while/Less_1 (1/1 flops)\n",
      "  map_1/while/Less (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
      "  map/while/Less_1 (1/1 flops)\n",
      "  map/while/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  BatchGather/mul_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  BatchGather/mul (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "2021-02-18 10:52:06.216830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-02-18 10:52:06.273087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2021-02-18 10:52:06.273707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2021-02-18 10:52:06.273915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:52:06.275417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-02-18 10:52:06.276541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-02-18 10:52:06.276795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-02-18 10:52:06.278247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-02-18 10:52:06.279414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-02-18 10:52:06.282539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-02-18 10:52:06.284882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2021-02-18 10:52:06.285168: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-02-18 10:52:06.290786: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3799900000 Hz\n",
      "2021-02-18 10:52:06.291685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562033313fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-18 10:52:06.291735: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-02-18 10:52:06.507919: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562034120cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-18 10:52:06.507983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2021-02-18 10:52:06.508001: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080, Compute Capability 6.1\n",
      "2021-02-18 10:52:06.511271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2021-02-18 10:52:06.512266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2021-02-18 10:52:06.512341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:52:06.512371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-02-18 10:52:06.512397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-02-18 10:52:06.512424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-02-18 10:52:06.512451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-02-18 10:52:06.512477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-02-18 10:52:06.512504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-02-18 10:52:06.516208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2021-02-18 10:52:06.516282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:52:06.519551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-02-18 10:52:06.519582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2021-02-18 10:52:06.519599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2021-02-18 10:52:06.519613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2021-02-18 10:52:06.526801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7414 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2021-02-18 10:52:06.528071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7611 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from training_masks/model.ckpt-2772\n",
      "I0218 10:52:06.532602 140447977408320 saver.py:1284] Restoring parameters from training_masks/model.ckpt-2772\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0218 10:52:08.125964 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2021-02-18 10:52:08.668030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2021-02-18 10:52:08.668433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2021-02-18 10:52:08.668479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:52:08.668489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-02-18 10:52:08.668498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-02-18 10:52:08.668507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-02-18 10:52:08.668517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-02-18 10:52:08.668526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-02-18 10:52:08.668535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-02-18 10:52:08.669607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2021-02-18 10:52:08.669640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-02-18 10:52:08.669647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2021-02-18 10:52:08.669653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2021-02-18 10:52:08.669658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2021-02-18 10:52:08.670447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7414 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2021-02-18 10:52:08.670772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7611 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from training_masks/model.ckpt-2772\n",
      "I0218 10:52:08.671931 140447977408320 saver.py:1284] Restoring parameters from training_masks/model.ckpt-2772\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0218 10:52:09.495230 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0218 10:52:09.495560 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 360 variables.\n",
      "I0218 10:52:09.934328 140447977408320 graph_util_impl.py:334] Froze 360 variables.\n",
      "INFO:tensorflow:Converted 360 variables to const ops.\n",
      "I0218 10:52:10.003311 140447977408320 graph_util_impl.py:394] Converted 360 variables to const ops.\n",
      "2021-02-18 10:52:10.177794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2021-02-18 10:52:10.178194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2021-02-18 10:52:10.178241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-02-18 10:52:10.178253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-02-18 10:52:10.178263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-02-18 10:52:10.178273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-02-18 10:52:10.178283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-02-18 10:52:10.178292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-02-18 10:52:10.178302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-02-18 10:52:10.179370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2021-02-18 10:52:10.179404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-02-18 10:52:10.179411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2021-02-18 10:52:10.179418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2021-02-18 10:52:10.179423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2021-02-18 10:52:10.180235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7414 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2021-02-18 10:52:10.180576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7611 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0218 10:52:10.529098 140447977408320 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "I0218 10:52:10.529645 140447977408320 builder_impl.py:640] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0218 10:52:10.529738 140447977408320 builder_impl.py:460] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: inference_graph_mask_rcnn_18_2/saved_model/saved_model.pb\n",
      "I0218 10:52:10.846254 140447977408320 builder_impl.py:425] SavedModel written to: inference_graph_mask_rcnn_18_2/saved_model/saved_model.pb\n",
      "INFO:tensorflow:Writing pipeline config file to inference_graph_mask_rcnn_18_2/pipeline.config\n",
      "I0218 10:52:10.869942 140447977408320 config_util.py:254] Writing pipeline config file to inference_graph_mask_rcnn_18_2/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "# ahora vamos a exportar este modelo como un grafo de inferencia. Este grafo se podrá usar para generar predicciones luego.\n",
    "# Debemos sustituir los parámetros de entrada [\"pipeline_config_path\",\"trained_checkpoint_prefix\",\"output_directory\"]\n",
    "# por los nuestros. Es recomendable elegir un nombre reconocible para la carpeta de salida, como por ejemplo\n",
    "# \"inference_graph\" seguido del modelo entrenado y  la fecha y la hora\n",
    "!python3 models/research/object_detection/export_inference_graph.py --input_type image_tensor \\\n",
    "--pipeline_config_path {training_dir}/temp.config \\\n",
    "--trained_checkpoint_prefix {training_dir}/{model_checkpoint_prefix} \\\n",
    "--output_directory {inference_graph_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 90\n",
      "Scales:            [0.25, 0.5, 1.0, 2.0]\n",
      "Aspect ratios:     [0.5, 1.0, 2.0]\n",
      "Width stride:      16.000000\n",
      "Height stride:     16.000000\n",
      "Features stride:   16.000000\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario_henar/tensorflow_object_detection/mario/scripts/tf_text_graph_common.py:318: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario_henar/tensorflow_object_detection/mario/scripts/tf_text_graph_common.py:319: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "2021-02-18 10:52:41.061927: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying sort_by_execution_order\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario_henar/tensorflow_object_detection/mario/scripts/tf_text_graph_common.py:329: The name tf.train.write_graph is deprecated. Please use tf.io.write_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ahora creamos un archivo graph.pbtxt con la estructura concreta necesaria para usar este modelo con openCV \n",
    "!python3 scripts/tf_text_graph_faster_rcnn.py \\\n",
    "--input {inference_graph_dir}/frozen_inference_graph.pb \\\n",
    "--config {training_dir}/{config_file_name} \\\n",
    "--output {inference_graph_dir}/graph.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pediciendo en imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debemos sustituir el parámetro -m por la carpeta donde está nuestro modelo exportado \n",
    "!python3 scripts/predict_on_images.py \\\n",
    "-i images_bb/test \\\n",
    "-o predictions_image_bb \\\n",
    "-m {inference_graph_dir} \\\n",
    "-l {training_dir}/label_map.pbtxt \\\n",
    "-f JPG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
